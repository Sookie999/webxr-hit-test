import {
  _SpatialAudioAttacherComponent,
  _SpatialWebAudioUpdaterComponent
} from "./chunk-FS355YOW.js";
import {
  AbstractAudioNode,
  _WebAudioParameterComponent
} from "./chunk-W2FO6UWU.js";
import {
  AbstractEngine
} from "./chunk-FCN7ZBEY.js";
import {
  Matrix,
  Quaternion,
  Vector3
} from "./chunk-SAE7R3H2.js";
import {
  EngineStore
} from "./chunk-DDXCXL26.js";
import {
  Observable
} from "./chunk-GCT36VBF.js";

// node_modules/@babylonjs/core/AudioV2/abstractAudio/audioEngineV2.js
var Instances = [];
var AudioEngineV2 = class {
  constructor(options) {
    this._mainBuses = /* @__PURE__ */ new Set();
    this._nodes = /* @__PURE__ */ new Set();
    this._defaultMainBus = null;
    this._parameterRampDuration = 0.01;
    Instances.push(this);
    if (typeof options.parameterRampDuration === "number") {
      this.parameterRampDuration = options.parameterRampDuration;
    }
  }
  /**
   * The default main bus that will be used for audio buses and sounds if their `outBus` option is not set.
   * @see {@link IAudioBusOptions.outBus}
   * @see {@link IAbstractSoundOptions.outBus}
   */
  get defaultMainBus() {
    if (this._mainBuses.size === 0) {
      return null;
    }
    if (!this._defaultMainBus) {
      this._defaultMainBus = Array.from(this._mainBuses)[0];
    }
    return this._defaultMainBus;
  }
  /**
   * The smoothing duration to use when changing audio parameters, in seconds. Defaults to `0.01` (10 milliseconds).
   *
   * Due to limitations in some browsers, it is not recommended to set this value to longer than `0.01` seconds.
   *
   * Setting this value to longer than `0.01` seconds may result in errors being throw when setting audio parameters.
   */
  get parameterRampDuration() {
    return this._parameterRampDuration;
  }
  set parameterRampDuration(value) {
    this._parameterRampDuration = Math.max(0, value);
  }
  /**
   * Releases associated resources.
   */
  dispose() {
    if (Instances.includes(this)) {
      Instances.splice(Instances.indexOf(this), 1);
    }
    const nodeIt = this._nodes.values();
    for (let next = nodeIt.next(); !next.done; next = nodeIt.next()) {
      next.value.dispose();
    }
    this._mainBuses.clear();
    this._nodes.clear();
    this._defaultMainBus = null;
  }
  /**
   * Unlocks the audio engine if it is locked.
   * - Note that the returned promise may already be resolved if the audio engine is already unlocked.
   * @returns A promise that is resolved when the audio engine is unlocked.
   */
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  unlockAsync() {
    return this.resumeAsync();
  }
  _addMainBus(mainBus) {
    this._mainBuses.add(mainBus);
    this._addNode(mainBus);
  }
  _removeMainBus(mainBus) {
    this._mainBuses.delete(mainBus);
    this._defaultMainBus = null;
    this._removeNode(mainBus);
  }
  _addNode(node) {
    this._nodes.add(node);
  }
  _removeNode(node) {
    this._nodes.delete(node);
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subProperties/abstractSpatialAudioListener.js
var _SpatialAudioListenerDefaults = {
  position: Vector3.Zero(),
  rotation: Vector3.Zero(),
  rotationQuaternion: new Quaternion()
};
function _HasSpatialAudioListenerOptions(options) {
  return options.listenerEnabled || options.listenerMinUpdateTime !== void 0 || options.listenerPosition !== void 0 || options.listenerRotation !== void 0 || options.listenerRotationQuaternion !== void 0;
}
var AbstractSpatialAudioListener = class {
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subProperties/spatialAudioListener.js
var _SpatialAudioListener = class extends AbstractSpatialAudioListener {
  constructor() {
    super();
    this._attacherComponent = null;
    this._attacherComponent = new _SpatialAudioAttacherComponent(this);
  }
  /** @internal */
  get isAttached() {
    return this._attacherComponent !== null && this._attacherComponent.isAttached;
  }
  /**
   * Attaches to a scene node.
   *
   * Detaches automatically before attaching to the given scene node.
   * If `sceneNode` is `null` it is the same as calling `detach()`.
   *
   * @param sceneNode The scene node to attach to, or `null` to detach.
   * @param useBoundingBox Whether to use the bounding box of the node for positioning. Defaults to `false`.
   * @param attachmentType Whether to attach to the node's position and/or rotation. Defaults to `PositionAndRotation`.
   */
  attach(sceneNode, useBoundingBox = false, attachmentType = 3) {
    if (!this._attacherComponent) {
      this._attacherComponent = new _SpatialAudioAttacherComponent(this);
    }
    this._attacherComponent.attach(sceneNode, useBoundingBox, attachmentType);
  }
  /**
   * Detaches from the scene node if attached.
   */
  detach() {
    this._attacherComponent?.detach();
  }
  /** @internal */
  dispose() {
    this._attacherComponent?.dispose();
    this._attacherComponent = null;
  }
  /** @internal */
  setOptions(options) {
    if (options.listenerMinUpdateTime !== void 0) {
      this.minUpdateTime = options.listenerMinUpdateTime;
    }
    if (options.listenerPosition) {
      this.position = options.listenerPosition.clone();
    }
    if (options.listenerRotationQuaternion) {
      this.rotationQuaternion = options.listenerRotationQuaternion.clone();
    } else if (options.listenerRotation) {
      this.rotation = options.listenerRotation.clone();
    } else {
      this.rotationQuaternion = _SpatialAudioListenerDefaults.rotationQuaternion.clone();
    }
    this.update();
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/subProperties/spatialWebAudioListener.js
var TmpMatrix = Matrix.Zero();
var TmpQuaternion = new Quaternion();
var TmpVector1 = Vector3.Zero();
var TmpVector2 = Vector3.Zero();
function _CreateSpatialAudioListener(engine, autoUpdate, minUpdateTime) {
  const listener = engine._audioContext.listener;
  if (listener.forwardX && listener.forwardY && listener.forwardZ && listener.positionX && listener.positionY && listener.positionZ && listener.upX && listener.upY && listener.upZ) {
    return new _SpatialWebAudioListener(engine, autoUpdate, minUpdateTime);
  } else {
    return new _SpatialWebAudioListenerFallback(engine, autoUpdate, minUpdateTime);
  }
}
var _AbstractSpatialWebAudioListener = class extends _SpatialAudioListener {
  /** @internal */
  constructor(engine, autoUpdate, minUpdateTime) {
    super();
    this._lastPosition = Vector3.Zero();
    this._lastRotation = Vector3.Zero();
    this._lastRotationQuaternion = new Quaternion();
    this.position = Vector3.Zero();
    this.rotation = Vector3.Zero();
    this.rotationQuaternion = new Quaternion();
    this._listener = engine._audioContext.listener;
    this.engine = engine;
    this._updaterComponent = new _SpatialWebAudioUpdaterComponent(this, autoUpdate, minUpdateTime);
  }
  /** @internal */
  dispose() {
    super.dispose();
    this._updaterComponent.dispose();
    this._updaterComponent = null;
  }
  /** @internal */
  get minUpdateTime() {
    return this._updaterComponent.minUpdateTime;
  }
  /** @internal */
  set minUpdateTime(value) {
    this._updaterComponent.minUpdateTime = value;
  }
  /** @internal */
  update() {
    if (this.isAttached) {
      this._attacherComponent?.update();
    } else {
      this._updatePosition();
      this._updateRotation();
    }
  }
  _updatePosition() {
    if (this._lastPosition.equalsWithEpsilon(this.position)) {
      return;
    }
    this._setWebAudioPosition(this.position);
    this._lastPosition.copyFrom(this.position);
  }
  _updateRotation() {
    if (!this._lastRotationQuaternion.equalsWithEpsilon(this.rotationQuaternion)) {
      TmpQuaternion.copyFrom(this.rotationQuaternion);
      this._lastRotationQuaternion.copyFrom(this.rotationQuaternion);
    } else if (!this._lastRotation.equalsWithEpsilon(this.rotation)) {
      Quaternion.FromEulerAnglesToRef(this.rotation.x, this.rotation.y, this.rotation.z, TmpQuaternion);
      this._lastRotation.copyFrom(this.rotation);
    } else {
      return;
    }
    Matrix.FromQuaternionToRef(TmpQuaternion, TmpMatrix);
    Vector3.TransformNormalToRef(Vector3.RightHandedForwardReadOnly, TmpMatrix, TmpVector1);
    Vector3.TransformNormalToRef(Vector3.Up(), TmpMatrix, TmpVector2);
    this._setWebAudioOrientation(TmpVector1, TmpVector2);
  }
};
var _SpatialWebAudioListener = class extends _AbstractSpatialWebAudioListener {
  constructor(engine, autoUpdate, minUpdateTime) {
    super(engine, autoUpdate, minUpdateTime);
    const listener = engine._audioContext.listener;
    this._forwardX = new _WebAudioParameterComponent(engine, listener.forwardX);
    this._forwardY = new _WebAudioParameterComponent(engine, listener.forwardY);
    this._forwardZ = new _WebAudioParameterComponent(engine, listener.forwardZ);
    this._positionX = new _WebAudioParameterComponent(engine, listener.positionX);
    this._positionY = new _WebAudioParameterComponent(engine, listener.positionY);
    this._positionZ = new _WebAudioParameterComponent(engine, listener.positionZ);
    this._upX = new _WebAudioParameterComponent(engine, listener.upX);
    this._upY = new _WebAudioParameterComponent(engine, listener.upY);
    this._upZ = new _WebAudioParameterComponent(engine, listener.upZ);
  }
  _setWebAudioPosition(position) {
    if (this.isAttached && (this._positionX.isRamping || this._positionY.isRamping || this._positionZ.isRamping)) {
      return;
    }
    this._positionX.targetValue = position.x;
    this._positionY.targetValue = position.y;
    this._positionZ.targetValue = position.z;
  }
  _setWebAudioOrientation(forward, up) {
    if (this.isAttached && (this._forwardX.isRamping || this._forwardY.isRamping || this._forwardZ.isRamping || this._upX.isRamping || this._upY.isRamping || this._upZ.isRamping)) {
      return;
    }
    this._forwardX.targetValue = forward.x;
    this._forwardY.targetValue = forward.y;
    this._forwardZ.targetValue = forward.z;
    this._upX.targetValue = up.x;
    this._upY.targetValue = up.y;
    this._upZ.targetValue = up.z;
  }
};
var _SpatialWebAudioListenerFallback = class extends _AbstractSpatialWebAudioListener {
  _setWebAudioPosition(position) {
    this._listener.setPosition(position.x, position.y, position.z);
  }
  _setWebAudioOrientation(forward, up) {
    this._listener.setOrientation(forward.x, forward.y, forward.z, up.x, up.y, up.z);
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/mainAudioOut.js
var _MainAudioOut = class extends AbstractAudioNode {
  constructor(engine) {
    super(
      engine,
      1
      /* AudioNodeType.HAS_INPUTS */
    );
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/webAudioMainOut.js
var _WebAudioMainOut = class extends _MainAudioOut {
  /** @internal */
  constructor(engine) {
    super(engine);
    this._setGainNode(new GainNode(engine._audioContext));
  }
  /** @internal */
  dispose() {
    super.dispose();
    this._volume.dispose();
    this._gainNode.disconnect();
    this._destinationNode.disconnect();
  }
  /** @internal */
  get _inNode() {
    return this._gainNode;
  }
  set _inNode(value) {
    if (this._gainNode === value) {
      return;
    }
    this._setGainNode(value);
  }
  /** @internal */
  get volume() {
    return this._volume.targetValue;
  }
  /** @internal */
  set volume(value) {
    this._volume.targetValue = value;
  }
  get _destinationNode() {
    return this.engine._audioDestination;
  }
  /** @internal */
  getClassName() {
    return "_WebAudioMainOut";
  }
  /** @internal */
  setVolume(value, options = null) {
    this._volume.setTargetValue(value, options);
  }
  _setGainNode(gainNode) {
    if (this._gainNode === gainNode) {
      return;
    }
    this._gainNode?.disconnect();
    gainNode.connect(this._destinationNode);
    this._volume = new _WebAudioParameterComponent(this.engine, gainNode.gain);
    this._gainNode = gainNode;
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/webAudioUnmuteUI.js
var _WebAudioUnmuteUI = class {
  /** @internal */
  constructor(engine, parentElement) {
    this._button = null;
    this._enabled = true;
    this._style = null;
    this._onStateChanged = () => {
      if (!this._button) {
        return;
      }
      if (this._engine.state === "running") {
        this._hide();
      } else {
        this._show();
      }
    };
    this._engine = engine;
    const parent = parentElement || EngineStore.LastCreatedEngine?.getInputElement()?.parentElement || document.body;
    const top = (parent?.offsetTop || 0) + 20;
    this._style = document.createElement("style");
    this._style.appendChild(document.createTextNode(`.babylonUnmute{position:absolute;top:${top}px;margin-left:20px;height:40px;width:60px;background-color:rgba(51,51,51,0.7);background-image:url("data:image/svg+xml;charset=UTF-8,%3Csvg%20version%3D%221.1%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2239%22%20height%3D%2232%22%20viewBox%3D%220%200%2039%2032%22%3E%3Cpath%20fill%3D%22white%22%20d%3D%22M9.625%2018.938l-0.031%200.016h-4.953q-0.016%200-0.031-0.016v-12.453q0-0.016%200.031-0.016h4.953q0.031%200%200.031%200.016v12.453zM12.125%207.688l8.719-8.703v27.453l-8.719-8.719-0.016-0.047v-9.938zM23.359%207.875l1.406-1.406%204.219%204.203%204.203-4.203%201.422%201.406-4.219%204.219%204.219%204.203-1.484%201.359-4.141-4.156-4.219%204.219-1.406-1.422%204.219-4.203z%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E");background-size:80%;background-repeat:no-repeat;background-position:center;background-position-y:4px;border:none;outline:none;transition:transform 0.125s ease-out;cursor:pointer;z-index:9999;}.babylonUnmute:hover{transform:scale(1.05)}`));
    document.head.appendChild(this._style);
    this._button = document.createElement("button");
    this._button.className = "babylonUnmute";
    this._button.id = "babylonUnmuteButton";
    this._button.addEventListener("click", () => {
      this._engine.unlockAsync();
    });
    parent.appendChild(this._button);
    this._engine.stateChangedObservable.add(this._onStateChanged);
  }
  /** @internal */
  dispose() {
    this._button?.remove();
    this._button = null;
    this._style?.remove();
    this._style = null;
    this._engine.stateChangedObservable.removeCallback(this._onStateChanged);
  }
  /** @internal */
  get enabled() {
    return this._enabled;
  }
  set enabled(value) {
    this._enabled = value;
    if (value) {
      if (this._engine.state !== "running") {
        this._show();
      }
    } else {
      this._hide();
    }
  }
  _show() {
    if (!this._button) {
      return;
    }
    this._button.style.display = "block";
  }
  _hide() {
    if (!this._button) {
      return;
    }
    this._button.style.display = "none";
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/webAudioEngine.js
var FormatMimeTypes = {
  aac: "audio/aac",
  ac3: "audio/ac3",
  flac: "audio/flac",
  m4a: "audio/mp4",
  mp3: 'audio/mpeg; codecs="mp3"',
  mp4: "audio/mp4",
  ogg: 'audio/ogg; codecs="vorbis"',
  wav: "audio/wav",
  webm: 'audio/webm; codecs="vorbis"'
};
var _WebAudioEngine = class extends AudioEngineV2 {
  /** @internal */
  constructor(options = {}) {
    super(options);
    this._audioContextStarted = false;
    this._destinationNode = null;
    this._invalidFormats = /* @__PURE__ */ new Set();
    this._isUpdating = false;
    this._listener = null;
    this._listenerAutoUpdate = true;
    this._listenerMinUpdateTime = 0;
    this._pauseCalled = false;
    this._resumeOnInteraction = true;
    this._resumeOnPause = true;
    this._resumeOnPauseRetryInterval = 1e3;
    this._resumeOnPauseTimerId = null;
    this._resumePromise = null;
    this._silentHtmlAudio = null;
    this._unmuteUI = null;
    this._updateObservable = null;
    this._validFormats = /* @__PURE__ */ new Set();
    this._volume = 1;
    this._isUsingOfflineAudioContext = false;
    this.isReadyPromise = new Promise((resolve) => {
      this._resolveIsReadyPromise = resolve;
    });
    this.stateChangedObservable = new Observable();
    this.userGestureObservable = new Observable();
    this._initAudioContextAsync = async () => {
      this._audioContext.addEventListener("statechange", this._onAudioContextStateChange);
      this._mainOut = new _WebAudioMainOut(this);
      this._mainOut.volume = this._volume;
      await this.createMainBusAsync("default");
    };
    this._onAudioContextStateChange = () => {
      if (this.state === "running") {
        clearInterval(this._resumeOnPauseTimerId);
        this._audioContextStarted = true;
        this._resumePromise = null;
      }
      if (this.state === "suspended" || this.state === "interrupted") {
        if (this._audioContextStarted && this._resumeOnPause && !this._pauseCalled) {
          clearInterval(this._resumeOnPauseTimerId);
          this._resumeOnPauseTimerId = setInterval(() => {
            this.resumeAsync();
          }, this._resumeOnPauseRetryInterval);
        }
      }
      this.stateChangedObservable.notifyObservers(this.state);
    };
    this._onUserGestureAsync = async () => {
      if (this._resumeOnInteraction) {
        await this._audioContext.resume();
      }
      if (!this._silentHtmlAudio) {
        this._silentHtmlAudio = document.createElement("audio");
        const audio = this._silentHtmlAudio;
        audio.controls = false;
        audio.preload = "auto";
        audio.loop = true;
        audio.src = "data:audio/wav;base64,UklGRjAAAABXQVZFZm10IBAAAAABAAEAgLsAAAB3AQACABAAZGF0YQwAAAAAAAEA/v8CAP//AQA=";
        audio.play();
      }
      this.userGestureObservable.notifyObservers();
    };
    this._startUpdating = () => {
      if (this._isUpdating) {
        return;
      }
      this._isUpdating = true;
      if (this.state === "running") {
        this._update();
      } else {
        const callback = () => {
          if (this.state === "running") {
            this._update();
            this.stateChangedObservable.removeCallback(callback);
          }
        };
        this.stateChangedObservable.add(callback);
      }
    };
    this._update = () => {
      if (this._updateObservable?.hasObservers()) {
        this._updateObservable.notifyObservers();
        requestAnimationFrame(this._update);
      } else {
        this._isUpdating = false;
      }
    };
    if (typeof options.listenerAutoUpdate === "boolean") {
      this._listenerAutoUpdate = options.listenerAutoUpdate;
    }
    if (typeof options.listenerMinUpdateTime === "number") {
      this._listenerMinUpdateTime = options.listenerMinUpdateTime;
    }
    this._volume = options.volume ?? 1;
    if (options.audioContext) {
      this._isUsingOfflineAudioContext = options.audioContext instanceof OfflineAudioContext;
      this._audioContext = options.audioContext;
    } else {
      this._audioContext = new AudioContext();
    }
    if (!options.disableDefaultUI) {
      this._unmuteUI = new _WebAudioUnmuteUI(this, options.defaultUIParentElement);
    }
  }
  /** @internal */
  async _initAsync(options) {
    this._resumeOnInteraction = typeof options.resumeOnInteraction === "boolean" ? options.resumeOnInteraction : true;
    this._resumeOnPause = typeof options.resumeOnPause === "boolean" ? options.resumeOnPause : true;
    this._resumeOnPauseRetryInterval = options.resumeOnPauseRetryInterval ?? 1e3;
    document.addEventListener("click", this._onUserGestureAsync);
    await this._initAudioContextAsync();
    if (_HasSpatialAudioListenerOptions(options)) {
      this._listener = _CreateSpatialAudioListener(this, this._listenerAutoUpdate, this._listenerMinUpdateTime);
      this._listener.setOptions(options);
    }
    this._resolveIsReadyPromise();
  }
  /** @internal */
  get currentTime() {
    return this._audioContext.currentTime ?? 0;
  }
  /** @internal */
  get _inNode() {
    return this._audioContext.destination;
  }
  /** @internal */
  get mainOut() {
    return this._mainOut;
  }
  /** @internal */
  get listener() {
    return this._listener ?? (this._listener = _CreateSpatialAudioListener(this, this._listenerAutoUpdate, this._listenerMinUpdateTime));
  }
  /** @internal */
  get state() {
    return this._isUsingOfflineAudioContext ? "running" : this._audioContext.state;
  }
  /** @internal */
  get volume() {
    return this._volume;
  }
  /** @internal */
  set volume(value) {
    if (this._volume === value) {
      return;
    }
    this._volume = value;
    if (this._mainOut) {
      this._mainOut.volume = value;
    }
  }
  /**
   * This property should only be used by the legacy audio engine.
   * @internal
   * */
  get _audioDestination() {
    return this._destinationNode ? this._destinationNode : this._destinationNode = this._audioContext.destination;
  }
  set _audioDestination(value) {
    this._destinationNode = value;
  }
  /**
   * This property should only be used by the legacy audio engine.
   * @internal
   */
  get _unmuteUIEnabled() {
    return this._unmuteUI ? this._unmuteUI.enabled : false;
  }
  set _unmuteUIEnabled(value) {
    if (this._unmuteUI) {
      this._unmuteUI.enabled = value;
    }
  }
  /** @internal */
  async createBusAsync(name, options = {}) {
    const module = await import("./webAudioBus-WOQDLFVN.js");
    const bus = new module._WebAudioBus(name, this, options);
    await bus._initAsync(options);
    return bus;
  }
  /** @internal */
  async createMainBusAsync(name, options = {}) {
    const module = await import("./webAudioMainBus-ZHYFHSWP.js");
    const bus = new module._WebAudioMainBus(name, this);
    await bus._initAsync(options);
    return bus;
  }
  /** @internal */
  async createMicrophoneSoundSourceAsync(name, options) {
    let mediaStream;
    try {
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    } catch (e) {
      throw new Error("Unable to access microphone: " + e);
    }
    return await this.createSoundSourceAsync(name, new MediaStreamAudioSourceNode(this._audioContext, { mediaStream }), {
      outBusAutoDefault: false,
      ...options
    });
  }
  /** @internal */
  async createSoundAsync(name, source, options = {}) {
    const module = await import("./webAudioStaticSound-W5NGR4HE.js");
    const sound = new module._WebAudioStaticSound(name, this, options);
    await sound._initAsync(source, options);
    return sound;
  }
  /** @internal */
  async createSoundBufferAsync(source, options = {}) {
    const module = await import("./webAudioStaticSound-W5NGR4HE.js");
    const soundBuffer = new module._WebAudioStaticSoundBuffer(this);
    await soundBuffer._initAsync(source, options);
    return soundBuffer;
  }
  /** @internal */
  async createSoundSourceAsync(name, source, options = {}) {
    const module = await import("./webAudioSoundSource-COMK5OYF.js");
    const soundSource = new module._WebAudioSoundSource(name, source, this, options);
    await soundSource._initAsync(options);
    return soundSource;
  }
  /** @internal */
  async createStreamingSoundAsync(name, source, options = {}) {
    const module = await import("./webAudioStreamingSound-VKXHSIKF.js");
    const sound = new module._WebAudioStreamingSound(name, this, options);
    await sound._initAsync(source, options);
    return sound;
  }
  /** @internal */
  dispose() {
    super.dispose();
    this._listener?.dispose();
    this._listener = null;
    if (this._audioContext.state !== "closed" && !this._isUsingOfflineAudioContext) {
      this._audioContext.close();
    }
    document.removeEventListener("click", this._onUserGestureAsync);
    this._audioContext.removeEventListener("statechange", this._onAudioContextStateChange);
    this._silentHtmlAudio?.remove();
    this._updateObservable?.clear();
    this._updateObservable = null;
    this._unmuteUI?.dispose();
    this._unmuteUI = null;
    this.stateChangedObservable.clear();
  }
  /** @internal */
  flagInvalidFormat(format) {
    this._invalidFormats.add(format);
  }
  /** @internal */
  isFormatValid(format) {
    if (this._validFormats.has(format)) {
      return true;
    }
    if (this._invalidFormats.has(format)) {
      return false;
    }
    const mimeType = FormatMimeTypes[format];
    if (mimeType === void 0) {
      return false;
    }
    const audio = new Audio();
    if (audio.canPlayType(mimeType) === "") {
      this._invalidFormats.add(format);
      return false;
    }
    this._validFormats.add(format);
    return true;
  }
  /** @internal */
  async pauseAsync() {
    await this._audioContext.suspend();
    this._pauseCalled = true;
  }
  /** @internal */
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  resumeAsync() {
    this._pauseCalled = false;
    if (this._resumePromise) {
      return this._resumePromise;
    }
    this._resumePromise = this._audioContext.resume();
    return this._resumePromise;
  }
  /** @internal */
  setVolume(value, options = null) {
    if (this._mainOut) {
      this._mainOut.setVolume(value, options);
    } else {
      throw new Error("Main output not initialized yet.");
    }
  }
  /** @internal */
  _addMainBus(mainBus) {
    super._addMainBus(mainBus);
  }
  /** @internal */
  _removeMainBus(mainBus) {
    super._removeMainBus(mainBus);
  }
  /** @internal */
  _addNode(node) {
    super._addNode(node);
  }
  /** @internal */
  _removeNode(node) {
    super._removeNode(node);
  }
  /** @internal */
  _addUpdateObserver(callback) {
    if (!this._updateObservable) {
      this._updateObservable = new Observable();
    }
    this._updateObservable.add(callback);
    this._startUpdating();
  }
  _removeUpdateObserver(callback) {
    if (this._updateObservable) {
      this._updateObservable.removeCallback(callback);
    }
  }
};

// node_modules/@babylonjs/core/Audio/audioEngine.js
AbstractEngine.AudioEngineFactory = (hostElement, audioContext, audioDestination) => {
  return new AudioEngine(hostElement, audioContext, audioDestination);
};
var AudioEngine = class {
  /**
   * The master gain node defines the global audio volume of your audio engine.
   */
  get masterGain() {
    return this._masterGain;
  }
  set masterGain(value) {
    this._masterGain = this._v2.mainOut._inNode = value;
  }
  /**
   * Defines if the audio engine relies on a custom unlocked button.
   * In this case, the embedded button will not be displayed.
   */
  get useCustomUnlockedButton() {
    return this._useCustomUnlockedButton;
  }
  set useCustomUnlockedButton(value) {
    this._useCustomUnlockedButton = value;
    this._v2._unmuteUIEnabled = !value;
  }
  /**
   * Gets the current AudioContext if available.
   */
  get audioContext() {
    if (this._v2.state === "running") {
      this._triggerRunningStateAsync();
    }
    return this._v2._audioContext;
  }
  /**
   * Instantiates a new audio engine.
   *
   * @param hostElement defines the host element where to display the mute icon if necessary
   * @param audioContext defines the audio context to be used by the audio engine
   * @param audioDestination defines the audio destination node to be used by audio engine
   */
  constructor(hostElement = null, audioContext = null, audioDestination = null) {
    this._audioContext = null;
    this._tryToRun = false;
    this._useCustomUnlockedButton = false;
    this.canUseWebAudio = true;
    this.WarnedWebAudioUnsupported = false;
    this.isMP3supported = false;
    this.isOGGsupported = false;
    this.unlocked = false;
    this.onAudioUnlockedObservable = new Observable();
    this.onAudioLockedObservable = new Observable();
    const v2 = new _WebAudioEngine({
      audioContext: audioContext ? audioContext : void 0,
      defaultUIParentElement: hostElement?.parentElement ? hostElement.parentElement : void 0
    });
    v2._unmuteUIEnabled = false;
    this._masterGain = new GainNode(v2._audioContext);
    v2._audioDestination = audioDestination;
    v2.stateChangedObservable.add((state) => {
      if (state === "running") {
        this.unlocked = true;
        this.onAudioUnlockedObservable.notifyObservers(this);
      } else {
        this.unlocked = false;
        this.onAudioLockedObservable.notifyObservers(this);
      }
    });
    v2._initAsync({ resumeOnInteraction: false }).then(() => {
      v2.mainOut._inNode = this._masterGain;
      v2.stateChangedObservable.notifyObservers(v2.state);
    });
    this.isMP3supported = v2.isFormatValid("mp3");
    this.isOGGsupported = v2.isFormatValid("ogg");
    this._v2 = v2;
  }
  /**
   * Flags the audio engine in Locked state.
   * This happens due to new browser policies preventing audio to autoplay.
   */
  lock() {
    this._v2._audioContext.suspend();
    if (!this._useCustomUnlockedButton) {
      this._v2._unmuteUIEnabled = true;
    }
  }
  /**
   * Unlocks the audio engine once a user action has been done on the dom.
   * This is helpful to resume play once browser policies have been satisfied.
   */
  unlock() {
    if (this._audioContext?.state === "running") {
      if (!this.unlocked) {
        this.unlocked = true;
        this.onAudioUnlockedObservable.notifyObservers(this);
      }
      return;
    }
    this._triggerRunningStateAsync();
  }
  /** @internal */
  _resumeAudioContextOnStateChange() {
    this._audioContext?.addEventListener("statechange", () => {
      if (this.unlocked && this._audioContext?.state !== "running") {
        this._resumeAudioContextAsync();
      }
    }, {
      once: true,
      passive: true,
      signal: AbortSignal.timeout(3e3)
    });
  }
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  _resumeAudioContextAsync() {
    if (this._v2._isUsingOfflineAudioContext) {
      return Promise.resolve();
    }
    return this._v2._audioContext.resume();
  }
  /**
   * Destroy and release the resources associated with the audio context.
   */
  dispose() {
    this._v2.dispose();
    this.onAudioUnlockedObservable.clear();
    this.onAudioLockedObservable.clear();
  }
  /**
   * Gets the global volume sets on the master gain.
   * @returns the global volume if set or -1 otherwise
   */
  getGlobalVolume() {
    return this.masterGain.gain.value;
  }
  /**
   * Sets the global volume of your experience (sets on the master gain).
   * @param newVolume Defines the new global volume of the application
   */
  setGlobalVolume(newVolume) {
    this.masterGain.gain.value = newVolume;
  }
  /**
   * Connect the audio engine to an audio analyser allowing some amazing
   * synchronization between the sounds/music and your visualization (VuMeter for instance).
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#using-the-analyser
   * @param analyser The analyser to connect to the engine
   */
  connectToAnalyser(analyser) {
    if (this._connectedAnalyser) {
      this._connectedAnalyser.stopDebugCanvas();
    }
    this._connectedAnalyser = analyser;
    this.masterGain.disconnect();
    this._connectedAnalyser.connectAudioNodes(this.masterGain, this._v2._audioContext.destination);
  }
  async _triggerRunningStateAsync() {
    if (this._tryToRun) {
      return;
    }
    this._tryToRun = true;
    await this._resumeAudioContextAsync();
    this._tryToRun = false;
    this.unlocked = true;
    this.onAudioUnlockedObservable.notifyObservers(this);
  }
};
//# sourceMappingURL=chunk-DVWIJT5I.js.map
